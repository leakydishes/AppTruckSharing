{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leakydishes/AppTruckSharing/blob/main/legacy_files/embeddings_qdrant_MiniLM_L6_v2_384.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"chatbot-title\"><b>AI Chatbot: </b> Alcohol and Drug Foundation (ADF)</div>\n",
        "\n",
        "<div class=\"chatbot-authors\"><b>Project Manager: </b>Dotahn</div>\n",
        "\n",
        "<div class=\"chatbot-authors\"><b>Authored by (interns): </b>Te' Claire and Khuzaima Jamil</div>\n",
        "\n",
        "<div class=\"chatbot-dates\"><b>Dates: </b>December 2023/ January, February 2024</div>\n",
        "\n",
        "<div class=\"chatbot-github\"><b>GitHub Repo: </b>\n",
        "<a href=\"https://github.com/Dotahn/ADFAIChatbot-Internship/tree/main\"> Github Link</a></div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"chatbot-section-header\"><b>Overview: </b>The aim of this project is to utilising an API to seamlessly integrate natural language capabilities (LLM models) into a chat application customised to Alcohol and Drug Foundation (ADF) website (https://adf.org.au/), while respecting ADF Artifical Intelligence Ethical Framework.\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"chatbot-sub-section\"><b>embeddings_qdrant.ipynb: </b></div>\n",
        "\n",
        "<div class=\"chatbot-sub-section\">\n",
        "  <i>Python script #3.5</i>\n",
        "  <br>\n",
        "  <ol>\n",
        "    <li>Embeddings & Tokenizing, text into individual words upload to Qdrant</li>\n",
        "    <li>Creates Knowledge Base for Generative Component</li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "gMpivhwa84or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lEla4KOyN2pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Overview:\n",
        "\n",
        "##Database:\n",
        "######Qdrant [12], [13], [14]\n",
        "*   Qdrant functions as a database and search engine for vectors, storing neural embeddings and the metadata (payload).\n",
        "*    It uses an API to store, search, and manage vectors with an additional payload (metadata). This enables faster and more accurate retrieval of unstructured data.\n",
        "*   An opensource alternative to Pinecone\n",
        "*   Qdrant DB stores data in document/JSON format.\n",
        "*   Qdrant and FlowiseAI [24].\n",
        "\n",
        "##RAG:\n",
        "1. **Embedding:** Embed your documents with an embedding model. Embedding a document means transforming its sentences or chunks of words into a vector of numbers. The idea is that sentences that are similar to each other should be close in terms of distance between its vectors and sentences that are different should be further away.\n",
        "2. **Vector Store:** Once you've got a list of numbers, you can store them in a vector store like ChromaDB, FAISS, or Pinecone. A vector store is like a database but as the name says, it indexes and stores vector embeddings for fast retrieval and similarity search.\n",
        "3. **Query:** Now that your document is embedded and stored, when you ask a specific question to an LLM, it will embed your query and find in the vector store the sentences that are the closest to your question in terms of cosine similarity for example.\n",
        "4. **Answering Your Question:** Once the closest sentences have been found, they are injected into the prompt.\n",
        "\n",
        "##### Embedding Models:\n",
        "1. **GPT4 (OpenAI)**\n",
        "  - Model: text-embedding-ada-002\n",
        "  - Outputfile name: embeddings_text_embedding_ada_002_1536\n",
        "  - Vector Dimensions (1536)\n",
        "\n",
        "2. **Mixtral vanilla**\n",
        "  - Model: mixtral-7b-8expert\n",
        "  - Outputfile name: embeddings_mixtral_7b_8expert_1024\n",
        "  - Vector Dimensions (1024)\n",
        "mixtral-7b-8expert [27], [28], [29]\n",
        "- Vector Dimensions (1024)\n",
        "* Text Generation: Model is too large to load onto the free Inference API. To try the model, launch it on Inference Endpoints instead.\n",
        "\n",
        "- Mixtral 8x7B, uses open-weights that outperforms well-known models like GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B in human benchmarks [24].\n",
        "- What is MoE?\n",
        "- Mistral 7x8B employs a router to assign 2 out of its 8 experts to each token, providing access to a whopping 47 billion parameters. Despite actively utilizing only 13 billion parameters during inference, Mixtral 8x7B outpaces the 70B Llama 2 on most benchmarks, achieving an impressive six times faster inference.\n",
        "- Mixtral 8x7B [25] is an LLM that is more complex than Mistral 7B [26]\n",
        "Mixtral AX7 (additional)\n",
        "https://miro.medium.com/v2/resize:fit:640/format:webp/1*Vr0GjhpAlAZ8oLZjqImBNQ.png\n",
        "\n",
        "3. **Claude 2.1**\n",
        "  - Model: all-mpnet-base-v2\n",
        "  - Outputfile name: embeddings_mpnet_base_v2_384\n",
        "  - Vector Dimensions (384)\n",
        "MPNET Base V2 with Sentence Embeddings\n",
        "- all-mpnet-base-v2 https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
        "Model all-mpnet-base-v [25], [27]\n",
        "*   Performance Sentence Embeddings (14 Datasets) 69.57\n",
        "*   Performance Semantic Search (6 Datasets) 57.02\n",
        "*   Avg. Performance 63.30\n",
        "*   Speed 2800\n",
        "*   Model Size 420 MB\n",
        "\n",
        "<br>\n",
        "\n",
        "### Embeddings\n",
        "The Washington Post found in Googles C4 dataset, that the quality and quantity of embeddings are equally important to the model LLM training [3], [4]. When to fine-tuning models, the industry typically uses datasets (high-quality) to protect users from some unwanted content.\\\n",
        "\n",
        "*   The size of the embedding depends on the model that we choose.\n",
        "*   The higher the cost, the more dimensions the embeddings will have, resulting in more accurate results, ie. Ada (1024), Babbage (2048), Curie (4096), Davinci (12288) [5].\n",
        "<br>\n",
        "\n",
        "- Vector Embedding is model-specific.\n",
        "- Model to Model embedding may change.\n",
        "- Techniques: Word Embeddings, Sentence Embeddings, or Contextual embedding, vector embeddings provide a compact and meaningful representation of textual data.\n",
        "\n",
        "\n",
        "#### Additional Research\n",
        "2. BGE Embedding [21], [22]\n",
        "- bge-large-en-v1.5 https://huggingface.co/BAAI/bge-large-en-v1.5\n",
        "- https://huggingface.co/BAAI/bge-large-en-v1.5\n",
        "- BGE embedding is a general Embedding Model\n",
        "- Different from other embedding models using mean pooling, BGE uses the last hidden state of [cls] as the sentence embedding: sentence_embeddings = model_output[0][:, 0]. If you use mean pooling, there will be a significant decrease in performance\n",
        "- You can also use the bge models with sentence-transformers.\n",
        "- First, you pass your input through the transformer model, then you select the last hidden state of the first token (i.e., [CLS]) as the sentence embedding.\n",
        "\n",
        "\n",
        "##### Notes:\n",
        "- As data is represented as vectors (high-dimensional space) with a 'id' and a 'payload', the elements need to be stored in a 'Collection' (a vector database like Qdrant).\n",
        "- Where each element of the vector corresponds to a specific feature or attribute of the object.\n",
        "- Vector translate dat into binary for similarity search (distance metrics), ie. Euclidean distance, cosine similarity. Vector database that can perform similarity searches increase efficiency in returning best distnace metrics.\n",
        "\n",
        "##### Qdrant Cloud\n",
        "*   API https://cloud.qdrant.io/\n",
        "*   Create a new 'cluster' using the basic free tier version.\n",
        "*   Cluster: 'adf_chatbot_embeddings'\n",
        "*   Note: a cluster can have several Collections, each collection can contain one or more points (vectors).\n",
        "*   Authorised with Github & API key added to JSON secrets file (qdrantKey)\n",
        "<br>\n",
        "\n",
        "##### Pre-requisites\n",
        "1. Qdrant server instance (local Docker container)\n",
        "2. The qdrant-client library to interact with the vector database.\n",
        "3. A model API key or Hugging Faces Library\n",
        "<br>\n",
        "\n",
        "##### RAM Usage Rate Google Collab\n",
        "- Usage rate: approximately 5.53 per hour V100 (High-ram)\n",
        "- Usage rate: approximately 1.96 per hour T4 GPU (Low-ram)\n",
        "- Usage rate: approximately 2.05 per hour T4 GPU (High-ram)"
      ],
      "metadata": {
        "id": "IvAZORq9lSKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Research\n",
        "\n",
        "### Embeddings\n",
        "The Washington Post found in Googles C4 dataset, that the quality and quantity of embeddings are equally important to the model LLM training [3], [4]. When to fine-tuning models, the industry typically uses datasets (high-quality) to protect users from some unwanted content.\\\n",
        "\n",
        "*   The size of the embedding depends on the model that we choose.\n",
        "*   The higher the cost, the more dimensions the embeddings will have, resulting in more accurate results, ie. Ada (1024), Babbage (2048), Curie (4096), Davinci (12288) [5].\n",
        "<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FnUeORMIx1D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FxQPQM3VOLfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "<br>\n",
        "[1] https://blog.apify.com/what-is-data-labeling-in-ai/\n",
        "<br>\n",
        "[2] https://blog.apify.com/what-is-retrieval-augmented-generation/\n",
        "<br>\n",
        "[3] https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/\n",
        "<br>\n",
        "[4] https://www.semanticscholar.org/paper/Documenting-the-English-Colossal-Clean-Crawled-Dodge-Sap/40c3327a6ddb0603b6892344509c7f428ab43d81?itid=lk_inline_enhanced-template\n",
        "<br>\n",
        "[5] https://huggingface.co/spaces/mteb/leaderboard\n",
        "<br>\n",
        "[6] https://neon.tech/blog/mistral-7b-and-baai-on-workers-ai-vs-openai-models-for-rag\n",
        "<br>\n",
        "[7] https://neon.tech/blog/mistral-7b-and-baai-on-workers-ai-vs-openai-models-for-rag\n",
        "<br>\n",
        "[8] https://arxiv.org/pdf/2310.06825.pdf\n",
        "<br>\n",
        "[9] https://docs.mistral.ai/\n",
        "<br>\n",
        "[10] https://blog.stackademic.com/building-a-multidocument-chatbot-using-mistral-7b-qdrant-and-langchain-1d9982186736\n",
        "<br>\n",
        "[11] https://github.com/openai/openai-cookbook/blob/main/examples/vector_databases/qdrant/Getting_started_with_Qdrant_and_OpenAI.ipynb\n",
        "<br>\n",
        "[12] https://qdrant.tech/documentation/overview/\n",
        "<br>\n",
        "[13] https://sidgraph.medium.com/building-a-youtube-chatbot-using-langchain-qdrant-and-mistral-7b-in-depth-guide-d46a7ad2af61\n",
        "<br>\n",
        "[14] https://medium.com/@karanshingde/power-your-rag-application-using-qdrantdb-mistral-8x7b-moe-langchain-and-streamlit-15cd90ad4d49\n",
        "<br>\n",
        "[15] https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "<br>\n",
        "[16] https://mistral.ai/news/announcing-mistral-7b/\n",
        "<br>\n",
        "[17] https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac\n",
        "<br>\n",
        "[18] https://docs.flowiseai.com/integrations/vector-stores/qdrant\n",
        "<br>\n",
        "[19] https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
        "<br>\n",
        "[20] https://colab.research.google.com/github/qdrant/examples/blob/master/qdrant_101_getting_started/getting_started.ipynb\n",
        "<br>\n",
        "[21] https://github.com/FlagOpen/FlagEmbedding\n",
        "<br>\n",
        "[22] https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/baai_general_embedding\n",
        "<br>\n",
        "[23] https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3\n",
        "<br>\n",
        "[24] https://ai.plainenglish.io/mixture-of-experts-comprehensive-exploration-of-mixtral-8x7b-973184c1de27\n",
        "<br>\n",
        "[25] https://arxiv.org/pdf/2401.04088.pdf\n",
        "<br>\n",
        "[26] https://arxiv.org/pdf/2310.06825.pdf\n",
        "<br>\n",
        "[27] https://towardsdatascience.com/mistral-ai-vs-meta-comparing-top-open-source-llms-565c1bc1516e\n",
        "<br>\n",
        "[28] https://huggingface.co/DiscoResearch/mixtral-7b-8expert\n",
        "<br>\n",
        "[29] https://huggingface.co/docs/transformers/model_doc/mixtral"
      ],
      "metadata": {
        "id": "2wcDdap297pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up\n",
        "#### Install Dependencies"
      ],
      "metadata": {
        "id": "G9ZiuPYW9Qlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "!pip install -q torch==2.1.0\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U langchain\n",
        "!pip install -q -U ctransformers[cuda]\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9lyuyLUP0gz",
        "outputId": "44100bf8-776b-45d0-899b-43c1d71e2c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Collecting torch>=1.6.0 (from sentence-transformers)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e177a402f59d3582cd18f4252a0052268d7597157e7c5b9bc406b9fd83611974\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, torch, sentence-transformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.23.post1 requires torch==2.1.2, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99 torch-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector database\n",
        "!pip install qdrant_client # Qdrant"
      ],
      "metadata": {
        "id": "Dw07e9o7l_Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a00473-e50a-4e6c-cb47-adb38638fd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.7.1-py3-none-any.whl (205 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/205.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m174.1/205.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.60.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio_tools-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.14.0 (from qdrant_client)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.23.5)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.10.14)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.0.7)\n",
            "Collecting protobuf<5.0dev,>=4.21.6 (from grpcio-tools>=1.41.0->qdrant_client)\n",
            "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.5.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.14.0->qdrant_client) (1.2.0)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, h11, httpcore, h2, grpcio-tools, httpx, qdrant_client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-tools-1.60.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.2 httpx-0.26.0 hyperframe-6.0.1 portalocker-2.8.2 protobuf-4.25.2 qdrant_client-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "tflSTpCMlHon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433d2774-3759-4e2b-adef-30d2c570e0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-2b602f55-cf7b-0a18-a5e5-39a308c246f8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Libraries"
      ],
      "metadata": {
        "id": "zorZ1lUQQBYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, warnings, json, uuid, requests, torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import notebook_login\n",
        "from google.colab import drive\n",
        "import datetime as dt"
      ],
      "metadata": {
        "id": "LeEzuZVxkefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RAG modules for RAG set up\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "# Vector database dependencies\n",
        "from qdrant_client import QdrantClient # Qdrant"
      ],
      "metadata": {
        "id": "zOlhhD4znvmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drive"
      ],
      "metadata": {
        "id": "iN6gkjb7PyjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and Mount Google Collab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "%cd /content/drive/MyDrive/ADFAIChatbot\n",
        "!ls"
      ],
      "metadata": {
        "id": "S2JeLIHbR5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4966b429-93d2-475c-d8ac-9b2857cc1dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1OP0r8cO6DFjxo5iF0yrlyXaRPCme93DI/ADFAIChatbot\n",
            "Docker\tmodels\tmodel_train  output_stats  python_scripts  secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load API Keys\n"
      ],
      "metadata": {
        "id": "CM48tpY2vtek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/ADFAIChatbot/secrets/secrets.json\"\n",
        "with open(file_path, \"r\") as file: # Read JSON\n",
        "      keys = json.load(file)\n",
        "      huggingfaceKey = keys[\"huggingfaceKey\"] # Hugging Face\n",
        "      supabase_token = keys[\"supabaseKey\"] # Supabase\n",
        "      supabase_url = keys[\"supabaseUrl\"] # Supabase\n",
        "      supabase_db = keys[\"supabaseDBPooler\"] # Supabase\n",
        "      qdrant_key_token = keys[\"qdrantKey\"] # Qdrant\n",
        "      qdrant_domain = keys[\"qdrantUrl\"] # Qdrant"
      ],
      "metadata": {
        "id": "cN50h2qqSL0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supabase Set Up\n",
        "- API request\n",
        "- GET Request (retrieve the data from table)\n",
        "- Convert Data to Dataframe"
      ],
      "metadata": {
        "id": "PiqB74DItHpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supabase\n",
        "supabase_url = supabase_url\n",
        "supabase_api_key = supabase_token\n",
        "table_name = \"cleandata\"\n",
        "\n",
        "# Set up Headers\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"apikey\": supabase_api_key,\n",
        "    \"Authorization\": f\"Bearer {supabase_api_key}\"\n",
        "}\n",
        "\n",
        "api_endpoint = f\"{supabase_url}/rest/v1/{table_name}\" # API endpoint\n",
        "response = requests.get(api_endpoint, headers=headers) # Fetch data\n",
        "\n",
        "# Request Check\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    # Convert JSON data to dataFrame\n",
        "    cleaned_data = pd.DataFrame(data)\n",
        "    print(\"Data loaded into DataFrame successfully.\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6OAOsZMtIL4",
        "outputId": "f8e3b4fd-f858-46e4-c12d-8160da1a7570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into DataFrame successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hugging faces"
      ],
      "metadata": {
        "id": "B8dsP15FPqfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Faces\n",
        "# Authentication\n",
        "from huggingface_hub import notebook_login\n",
        "!huggingface-cli login\n",
        "\n",
        "# Print user\n",
        "!huggingface-cli whoami"
      ],
      "metadata": {
        "id": "iYg8Z9M_PvtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23a3809-4121-407a-86e3-99c9c7d0fe69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "LeakyDishes\n",
            "\u001b[1morgs: \u001b[0m Alcohol-and-Drug-Foundation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TBDY8sgDlZnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Using ['text'] column from database for embeddings"
      ],
      "metadata": {
        "id": "N-WBn2hmtz9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ['text'] column for embeddings\n",
        "texts = cleaned_data['text'].tolist()  # Extract text from column\n",
        "\n",
        "# Extract text from column ['text']\n",
        "texts = cleaned_data['text'].tolist()\n",
        "cleaned_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "xwsLLSnKtsjm",
        "outputId": "681e52dc-edbc-47c0-ba17-83f1130afe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                        created_at  \\\n",
              "0  2971  2024-01-24T05:15:47.010268+00:00   \n",
              "1  2972  2024-01-24T05:15:47.010268+00:00   \n",
              "2  2973  2024-01-24T05:15:47.010268+00:00   \n",
              "3  2974  2024-01-24T05:15:47.010268+00:00   \n",
              "4  2975  2024-01-24T05:15:47.010268+00:00   \n",
              "\n",
              "                                            markdown  \\\n",
              "0  # Amyl nitrite\\n\\nLast published: November 23,...   \n",
              "1  # Anabolic steroids\\n\\nLast published: Novembe...   \n",
              "2  # Aspirin\\n\\nLast published: December 21, 2023...   \n",
              "3  # Benzodiazepines\\n\\nLast published: November ...   \n",
              "4  # Ayahuasca\\n\\nLast published: December 07, 20...   \n",
              "\n",
              "                                                text  \\\n",
              "0  amyl nitrite last published november 23, 2023 ...   \n",
              "1  anabolic steroids last published november 22, ...   \n",
              "2  aspirin last published december 21, 2023 what ...   \n",
              "3  benzodiazepines last published november 22, 20...   \n",
              "4  ayahuasca last published december 07, 2023 wha...   \n",
              "\n",
              "                                              url         last_updated  \\\n",
              "0     https://adf.org.au/drug-facts/amyl-nitrite/  2023-11-23T00:00:00   \n",
              "1         https://adf.org.au/drug-facts/steroids/  2023-11-22T00:00:00   \n",
              "2          https://adf.org.au/drug-facts/aspirin/  2023-12-21T00:00:00   \n",
              "3  https://adf.org.au/drug-facts/benzodiazepines/  2023-11-22T00:00:00   \n",
              "4        https://adf.org.au/drug-facts/ayahuasca/  2023-12-07T00:00:00   \n",
              "\n",
              "             title                                        description  \\\n",
              "0     amyl nitrite  amyl nitrites effects, a depressant known for ...   \n",
              "1         steroids  anabolic steroids, their medical uses, and non...   \n",
              "2           asprin  aspirin acetylsalicylic acid is a pharmaceutic...   \n",
              "3  benzodiazepines  understand benzodiazepines, their effects, ris...   \n",
              "4        ayahuasca  ayahuascas psychedelic effects, its traditiona...   \n",
              "\n",
              "             url_reduced  \n",
              "0  adf.org.au/drug-facts  \n",
              "1  adf.org.au/drug-facts  \n",
              "2  adf.org.au/drug-facts  \n",
              "3  adf.org.au/drug-facts  \n",
              "4  adf.org.au/drug-facts  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cebc223-dd12-4ed6-8048-b7ad23ee7222\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>markdown</th>\n",
              "      <th>text</th>\n",
              "      <th>url</th>\n",
              "      <th>last_updated</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>url_reduced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2971</td>\n",
              "      <td>2024-01-24T05:15:47.010268+00:00</td>\n",
              "      <td># Amyl nitrite\\n\\nLast published: November 23,...</td>\n",
              "      <td>amyl nitrite last published november 23, 2023 ...</td>\n",
              "      <td>https://adf.org.au/drug-facts/amyl-nitrite/</td>\n",
              "      <td>2023-11-23T00:00:00</td>\n",
              "      <td>amyl nitrite</td>\n",
              "      <td>amyl nitrites effects, a depressant known for ...</td>\n",
              "      <td>adf.org.au/drug-facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2972</td>\n",
              "      <td>2024-01-24T05:15:47.010268+00:00</td>\n",
              "      <td># Anabolic steroids\\n\\nLast published: Novembe...</td>\n",
              "      <td>anabolic steroids last published november 22, ...</td>\n",
              "      <td>https://adf.org.au/drug-facts/steroids/</td>\n",
              "      <td>2023-11-22T00:00:00</td>\n",
              "      <td>steroids</td>\n",
              "      <td>anabolic steroids, their medical uses, and non...</td>\n",
              "      <td>adf.org.au/drug-facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2973</td>\n",
              "      <td>2024-01-24T05:15:47.010268+00:00</td>\n",
              "      <td># Aspirin\\n\\nLast published: December 21, 2023...</td>\n",
              "      <td>aspirin last published december 21, 2023 what ...</td>\n",
              "      <td>https://adf.org.au/drug-facts/aspirin/</td>\n",
              "      <td>2023-12-21T00:00:00</td>\n",
              "      <td>asprin</td>\n",
              "      <td>aspirin acetylsalicylic acid is a pharmaceutic...</td>\n",
              "      <td>adf.org.au/drug-facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2974</td>\n",
              "      <td>2024-01-24T05:15:47.010268+00:00</td>\n",
              "      <td># Benzodiazepines\\n\\nLast published: November ...</td>\n",
              "      <td>benzodiazepines last published november 22, 20...</td>\n",
              "      <td>https://adf.org.au/drug-facts/benzodiazepines/</td>\n",
              "      <td>2023-11-22T00:00:00</td>\n",
              "      <td>benzodiazepines</td>\n",
              "      <td>understand benzodiazepines, their effects, ris...</td>\n",
              "      <td>adf.org.au/drug-facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2975</td>\n",
              "      <td>2024-01-24T05:15:47.010268+00:00</td>\n",
              "      <td># Ayahuasca\\n\\nLast published: December 07, 20...</td>\n",
              "      <td>ayahuasca last published december 07, 2023 wha...</td>\n",
              "      <td>https://adf.org.au/drug-facts/ayahuasca/</td>\n",
              "      <td>2023-12-07T00:00:00</td>\n",
              "      <td>ayahuasca</td>\n",
              "      <td>ayahuascas psychedelic effects, its traditiona...</td>\n",
              "      <td>adf.org.au/drug-facts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cebc223-dd12-4ed6-8048-b7ad23ee7222')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cebc223-dd12-4ed6-8048-b7ad23ee7222 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cebc223-dd12-4ed6-8048-b7ad23ee7222');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b1aebf8-61aa-4c87-a0a9-80ea39b03cad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b1aebf8-61aa-4c87-a0a9-80ea39b03cad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b1aebf8-61aa-4c87-a0a9-80ea39b03cad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain.document_loaders import TextLoader\n",
        "# documents = [Document(page_content=text, metadata={\"source\": \"local\"}) for text in texts]\n",
        "\n",
        "# Using only ['Text'] and additional columns for metadata\n",
        "documents = [Document(\n",
        "    page_content=record['text'],\n",
        "    metadata={\n",
        "        \"url\": record['url'],\n",
        "        \"title\": record['title'],\n",
        "        \"description\": record['description'],\n",
        "        \"last_updated\": record['last_updated']\n",
        "    }\n",
        ") for index, record in cleaned_data.iterrows()]"
      ],
      "metadata": {
        "id": "quSZ1FOUP43T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Set up RAG Components"
      ],
      "metadata": {
        "id": "viPBzvH3P9rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embeddings and Vectors\n",
        "1.   Text Splitting, Embeddings (using documents module)\n",
        "2.   Vector Store (using embeddings)"
      ],
      "metadata": {
        "id": "cUunO5DWQAEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Change chunk_size and chunk_overlap values depending on embeddings output preferred"
      ],
      "metadata": {
        "id": "aDvWd-YjD87l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text is split into smaller chunks\n",
        "# Chunk_size, chunk_overlap parameters define how text is split up\n",
        "def get_chunks(documents):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    return chunks\n",
        "\n",
        "text_chunks = get_chunks(documents)"
      ],
      "metadata": {
        "id": "chHDXDiuP9LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the Document first Object\n",
        "print(vars(text_chunks[0]))"
      ],
      "metadata": {
        "id": "4IMMi98bQFH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34494b1b-86cf-4e8b-9d35-a4641b54edf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_content': 'amyl nitrite last published november 23, 2023 what is amyl nitrite? amyl nitrite is a depressant which means it slows down the messages travelling between the brain and body. classified as an inhalant, it belongs to a class of drugs known as alkyl nitrites, which also includes butyl nitrite, isobutyl nitrite and isopropyl nitrite. amyl nitrite is a vasodilator. vasodilators are medicines that cause the blood vessels in the body to dilate and the involuntary smooth muscles to relax, lowering blood pressure. what does it look like? amyl nitrite is an extremely flammable and highly volatile oil that is clear or yellowish in colour and comes in a small glass bottle. it typically has a distinct smell similar to dirty socks. other names poppers, jungle juice, liquid gold, rush, purple haze and buzz. how is it used? amyl nitrite has been used medically in the past for the treatment of angina chest pain, and has been used for the treatment of cyanide poisoning. recreationally, its inhaled directly from the bottle and used to enhance sexual experiences or to experience a general sense of pleasure. historically, amyl nitrite has been used more by men who have sex with men.5 this is still common; however, it has also become a common party drug that is used more widely. effects of amyl nitrite there is no safe level of drug use. use of any drug always carries some risk. its important to be careful when taking any type of drug. amyl nitrite will affect everyone differently, based on size, weight and health whether the person is used to taking it whether other drugs are taken around the same time the amount taken the strength of the drug environment where the drug is taken amount of fresh air breathed while inhaling amount of physical activity before and after inhaling. the effects of amyl nitrate are usually felt straight away, and last for around two to five minutes. they include initial rush of euphoria flushing of the face increased heart rate dizziness warming sensations feelings of excitement involuntary muscle relaxation, especially the anal and vaginal sphincter nausea headaches low blood pressure slowed breathing skin irritation blurred vision nose bleeds psychological effects can include increased sensual awareness, visual distortions, lowered inhibitions and impaired judgement. headaches are common once the high passes. set and setting drugs that affect a persons mental state psychoactive drugs can also have varied effects depending on a persons mood or the environment they are in. this is often called set and setting set a persons state of mind, previous encounters with psychoactive drugs, and expectations of whats going to happen. for example, feelings of joy, sadness or anger can be magnified when a person drinks alcohol, or feelings of anxiety may be increased when using cannabis. setting the environment in which someone consumes a psychoactive drug  whether its known and familiar, who theyre with, if theyre indoors or outdoors, the type of music and light. for example, using psychoactive drugs in a calm, quiet and relaxed environment can lead to a different experience than in a noisy, crowded place. longterm effects the level of harm from the longterm use of amyl nitrite is generally low. however, long term effects can range from mild allergic reactions to potentially life threatening methaemoglobinaemia  a blood disorder that causes inadequate oxygen supply to body tissue. frequent use can also cause a rash around the mouth, nose and eyes, or any skin that is in regular contact with the vapour. this can look like a skin irritation. direct fluid contact with skin can cause burns and should be avoided. people who are anaemic, pregnant, have a heart condition, have high blood pressure, or have increased pressure within the skull head injury or brain haemorrhage should avoid using amyl nitrite as this can increase the risk of harmful effects. theres also a rare risk of maculopathy loss of vision most commonly associated with isopropyl nitrite. for people who have underlying glaucoma theres a risk of fluid pressure buildup within the eye. using amyl nitrite with other drugs the effects of using amyl nitrite with other drugs  including overthecounter or prescribed medications  can be unpredictable and dangerous. amyl nitrite  viagra or other erectile dysfunction medications a high risk that the person will lose consciousness due to a sudden and extreme drop in blood pressure. this may require immediate medical attention  call 000 in case of an emergency. amyl nitrite  amphetamines increased strain on the heart, placing whole body under extra stress. more on polydrug use polydrug use is a term for the use of more than one drug or type of drug at the same time or one after another.1 polydrug use can involve both illicit drugs and legal substances, such as alcohol and medications. read more withdrawal regular use of amyl nitrite use does not result in dependence. people who use it regularly shouldnt experience withdrawal symptoms, however it may take a few days for their body to get used to not having the drug in their system. health and safety some people might be unaware of how amyl nitrite should be used and incorrect use can be fatal. amyl nitrite liquid should not be ingested i.e. do not swallow, as it is a highly poisonous substance that can lead to blindness, brain damage, organ failure and death. its also a powerful irritant that can lead to burns to the face, skin and eyes. getting help if your use of stimulants is affecting your health, family, relationships, work, school, financial or other life situations, or youre concerned about a loved one, you can find help and support. call the national alcohol and other drug hotline on 1800 250 015 for free and confidential advice, information and counselling about alcohol and other drugs help and support services search find a service in your local area from our list. simply add your location or postcode and filter by service type to quickly discover help near you. if youre looking for other information or support options, send us an email at druginfoadf.org.au path2help  not sure what you are looking for? try our intuitive path2help tool and be matched with support information and services tailored to you.  amyl nitrite and the law  inhalant use is not a criminal offence in any australian state or territory. in recent years, some australian states and territories have revised police powers to intervene in inhalant use in two main ways. police are authorised to take away inhalants and related equipment pick up young people who are using inhalants, and release them into the care of a responsible person, or a place of safety. its also illegal in some states and territories to sell or supply products to someone if they believe they are to be used for inhaling. as of february 2020, the therapeutic goods administration tga have chosen to downschedule amyl nitrite to a schedule 3 medicine so that people will be able to purchase it from a pharmacist without needing a prescription. stateterritory legislation on inhalant sales it is an offence in queensland, western australia, victoria, south australia, and the northern territory to knowingly supply an inhalant to a person for the purpose of intentional inhalation. amyl nitrite statistics  in 2019, 4.8 of australians aged 14 years or older had used inhalants in their lifetime. between 2001 and 2019, general inhalant use among australians aged 14 years or older has increased from 0.4 to 1.4. in 2009, the prevalence of amyl nitrite use among gay and homosexually active men was at 32. references  print effects flushed face, headaches, impaired judgement, lowered inhibitions, nausea, nose bleeds, relaxation of involuntary muscles, rush of euphoria, sensual awareness, visual distortions, warming sensations aka buzz, jungle juice, liquid gold, poppers, purple haze, rush last updated 23 nov 2023  x', 'metadata': {'url': 'https://adf.org.au/drug-facts/amyl-nitrite/', 'title': 'amyl nitrite', 'description': 'amyl nitrites effects, a depressant known for a quick, euphoric rush. learn about its recreational use, risks, and impact on the mind and body.', 'last_updated': '2023-11-23T00:00:00'}, 'type': 'Document'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Models\n",
        "##### Embedding Models:\n",
        "1. **Claude 2.1**\n",
        "  - Model: all-mpnet-base-v2\n",
        "  - Outputfile name: embeddings_mpnet_base_v2_384\n",
        "  - Vector Dimensions (384)\n"
      ],
      "metadata": {
        "id": "jXTwOvg_vA4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# # Define the model\n",
        "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "# embedding_model = SentenceTransformer(model_name)\n",
        "\n",
        "# # Assuming text_chunks is a list of objects where each object has a 'text' attribute\n",
        "# # chunk_embeddings = [embedding_model.encode(chunk.page_content) for chunk in text_chunks]\n",
        "# chunk_embeddings = [(embedding_model.encode(chunk.page_content), chunk.metadata) for chunk in text_chunks]\n",
        "# print(chunk_embeddings[0])\n",
        "\n",
        "# model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\") # Old test\n",
        "# Reference https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
        "\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedding_model = SentenceTransformer(model_name)\n",
        "\n",
        "# Assuming text_chunks is a list of objects where each object has a 'text' attribute\n",
        "# chunk_embeddings = [embedding_model.encode(chunk.page_content) for chunk in text_chunks]\n",
        "chunk_embeddings = [(embedding_model.encode(chunk.page_content), chunk.metadata) for chunk in text_chunks]\n",
        "print(chunk_embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg3qFJQHpKPd",
        "outputId": "854c0722-5aa0-4d5c-e746-c91996dd999e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([-7.55856931e-02, -4.98172343e-02,  4.40601818e-03,  7.41399406e-03,\n",
            "        8.92868638e-03, -8.50624442e-02,  9.43308547e-02, -1.19197657e-02,\n",
            "        1.30912796e-01, -7.72167593e-02, -7.58649781e-02,  2.29869448e-02,\n",
            "       -8.12717080e-02,  8.66935030e-02, -8.45631361e-02,  5.80974072e-02,\n",
            "        2.80641112e-02, -4.32347804e-02,  1.84224620e-02,  9.98330042e-02,\n",
            "        3.31367701e-02,  6.14176132e-02, -2.84463298e-02,  1.28190508e-02,\n",
            "       -4.67867702e-02,  8.00715294e-03, -2.51103137e-02, -1.94146372e-02,\n",
            "        5.87008707e-03, -3.46222743e-02,  8.65346715e-02, -1.20327994e-02,\n",
            "       -8.57718587e-02,  1.78273432e-02, -2.91611031e-02,  2.27504503e-02,\n",
            "       -8.88954625e-02,  3.31952460e-02, -4.91235964e-02,  3.13298590e-02,\n",
            "        3.85471396e-02, -5.50916381e-02, -7.59686604e-02,  2.50346400e-03,\n",
            "        3.44036520e-03,  1.46877477e-02, -5.49393408e-02, -5.94010623e-03,\n",
            "        1.21789286e-02, -5.25474995e-02, -2.71602478e-02, -8.16488788e-02,\n",
            "        1.55356934e-03,  1.00651328e-02,  4.41658758e-02, -7.46629983e-02,\n",
            "       -4.01593745e-02, -5.83030768e-02, -7.09550083e-02,  5.75101329e-03,\n",
            "        4.55508754e-02,  7.98800811e-02, -1.63203720e-02, -4.61356230e-02,\n",
            "       -4.74116355e-02,  3.11569963e-02,  3.65474746e-02, -3.22106108e-02,\n",
            "        3.78978960e-02, -9.77434590e-02, -6.09039403e-02, -5.48158884e-02,\n",
            "        4.24948446e-02,  1.17512971e-01, -7.21909553e-02, -1.29575087e-02,\n",
            "        5.31016700e-02, -2.98486389e-02,  2.67078169e-02,  6.11506868e-04,\n",
            "        1.17572144e-01,  1.08651556e-01,  6.22258410e-02,  4.88193668e-02,\n",
            "        5.56807853e-02,  5.51531790e-03, -6.29165396e-03,  2.19700132e-02,\n",
            "       -1.41988071e-02,  8.43194127e-03,  2.83571966e-02,  7.62485191e-02,\n",
            "       -4.85594980e-02, -2.53615752e-02,  9.25618038e-02, -3.30247879e-02,\n",
            "       -8.12857747e-02,  1.99189186e-02, -2.85850093e-02,  1.08829066e-02,\n",
            "        4.34788913e-02,  4.67065349e-02, -7.51488730e-02, -9.99765620e-02,\n",
            "       -6.47526085e-02,  9.25300294e-04,  8.00900683e-02,  1.88204423e-02,\n",
            "        9.84922722e-02,  3.27717997e-02, -5.68991415e-02, -4.72274423e-03,\n",
            "       -1.18042564e-03, -5.41620143e-02, -1.05654612e-01,  4.24562506e-02,\n",
            "       -8.66052136e-02,  4.00355943e-02, -3.19813075e-03,  5.04195765e-02,\n",
            "       -2.55357642e-02, -4.06582467e-02,  2.38036811e-02, -3.76922302e-02,\n",
            "        4.73923199e-02,  6.50111660e-02, -5.63416891e-02,  1.82021259e-33,\n",
            "        2.54428051e-02,  3.35196033e-02,  2.37868652e-02,  4.34939787e-02,\n",
            "       -2.30908655e-02,  5.36501370e-02, -2.59392057e-02, -6.92080557e-02,\n",
            "        4.93142083e-02, -1.23632327e-02,  1.96059537e-03, -9.11846459e-02,\n",
            "       -1.11115955e-01,  9.25658494e-02,  3.84097546e-02,  2.62093777e-03,\n",
            "       -3.05719301e-02, -1.74474344e-02,  6.11169264e-02, -1.52598731e-02,\n",
            "        7.50749558e-03,  1.01722836e-01, -8.71588141e-02, -1.89241162e-03,\n",
            "       -9.76208597e-02,  3.33037004e-02, -1.35552764e-01,  1.57694053e-02,\n",
            "        7.30053857e-02, -1.96537049e-03,  4.45267335e-02, -3.18352580e-02,\n",
            "       -2.78864186e-02, -2.25131363e-02, -4.29142043e-02,  5.48678301e-02,\n",
            "        1.27619412e-02,  3.20426486e-02,  3.70428013e-03, -2.33562384e-02,\n",
            "        2.90599111e-02,  3.60305272e-02,  2.32244022e-02,  6.04437031e-02,\n",
            "       -2.60544363e-02,  5.30076623e-02, -9.82638747e-02,  8.47208351e-02,\n",
            "        1.91684943e-02, -4.46677096e-02,  4.92494851e-02, -3.13807800e-02,\n",
            "       -1.06481826e-02, -2.76641026e-02, -6.68990910e-02,  9.22702625e-02,\n",
            "       -2.54876390e-02, -8.47853199e-02,  1.14209682e-01,  1.54997036e-02,\n",
            "       -6.87201917e-02, -1.06851440e-02,  4.31999937e-02, -3.41381021e-02,\n",
            "        7.06150196e-03, -1.22468267e-02, -6.53815269e-02, -5.91827370e-02,\n",
            "       -1.72540452e-03,  3.85097675e-02, -2.25927420e-02,  1.77144706e-02,\n",
            "        8.51355121e-02, -4.80911173e-02,  7.47912144e-03, -2.80815680e-02,\n",
            "        4.66976613e-02, -5.39767882e-03,  3.41712050e-02, -1.05153238e-02,\n",
            "        4.67626378e-02, -9.47765037e-02,  3.66203897e-02, -1.45883681e-02,\n",
            "       -3.69103514e-02, -2.66918726e-03,  2.10993905e-02,  2.37312657e-03,\n",
            "       -4.80413623e-03, -1.00648834e-03,  1.88995227e-02, -6.83570951e-02,\n",
            "       -5.86198382e-02, -9.03866887e-02, -1.47074461e-02, -2.95297773e-33,\n",
            "        9.96574610e-02, -7.41303340e-02, -3.29420157e-02,  1.12482058e-02,\n",
            "        5.69108352e-02,  4.38263714e-02,  4.61068703e-03,  1.81196090e-02,\n",
            "       -1.98316458e-03,  1.75517462e-02,  5.63797653e-02, -1.81709006e-02,\n",
            "        4.04300578e-02,  1.02905706e-01, -1.30982986e-02,  2.85809152e-02,\n",
            "       -2.19541565e-02,  1.34726977e-02, -8.76846816e-03,  6.05056155e-03,\n",
            "       -5.87195680e-02,  8.28628987e-02,  4.84402291e-03,  6.40980573e-03,\n",
            "        9.08816885e-03,  3.57275270e-02, -1.45419510e-02, -7.56173134e-02,\n",
            "        6.14045821e-02,  4.14782539e-02,  4.49306108e-02,  5.99528514e-02,\n",
            "       -3.35620604e-02, -9.91566852e-02, -8.94378591e-03, -9.72108857e-04,\n",
            "        5.02706356e-02, -1.38031438e-01, -9.65235829e-02, -6.36599809e-02,\n",
            "        4.96886782e-02,  1.84673369e-02,  4.57875505e-02,  1.16216242e-02,\n",
            "       -2.84468047e-02,  6.47737831e-02, -4.88310680e-02, -7.18710572e-02,\n",
            "        1.41224731e-02,  3.78240757e-02,  4.18470949e-02,  3.46800461e-02,\n",
            "        9.03773529e-04,  9.44927335e-02, -8.18011165e-03, -6.75593363e-03,\n",
            "       -6.77098557e-02, -2.34641917e-02, -3.19373831e-02,  3.51338275e-02,\n",
            "       -5.59894145e-02,  5.20989001e-02, -9.15706251e-03, -6.92858323e-02,\n",
            "        6.05507707e-03, -2.19487585e-02, -9.96983144e-03,  6.08671829e-02,\n",
            "        7.20532909e-02, -7.07478672e-02, -4.53523174e-02,  4.45670374e-02,\n",
            "        8.02534670e-02,  5.86334206e-02,  4.14301604e-02, -2.62926449e-03,\n",
            "        3.90052758e-02, -6.20042942e-02,  2.25082859e-02, -1.26868086e-02,\n",
            "        1.12529984e-02,  2.29063518e-02, -5.94704188e-02, -2.25142669e-02,\n",
            "       -4.97760065e-02, -3.60729061e-02,  5.02931029e-02,  1.46904260e-01,\n",
            "       -4.00597379e-02, -5.33013642e-02,  8.67377501e-03, -4.14737947e-02,\n",
            "       -2.96532139e-02,  7.01613352e-02, -2.68920548e-02, -4.93088876e-08,\n",
            "       -4.93899435e-02, -9.66052040e-02,  4.93220799e-02, -2.01057307e-02,\n",
            "       -7.22520724e-02, -1.21458266e-02,  9.53720212e-02,  3.64760123e-02,\n",
            "       -1.01684046e-03, -1.13081587e-02,  4.83176857e-03,  9.23372656e-02,\n",
            "       -5.17147779e-02, -1.43987243e-03,  4.61948244e-03,  4.05104049e-02,\n",
            "       -1.68704689e-02, -1.42748859e-02, -6.35459507e-03, -5.78819513e-02,\n",
            "       -3.32531109e-02,  3.52577120e-02, -1.91340130e-02,  1.51748126e-02,\n",
            "        3.90341468e-02, -3.14280502e-02,  1.66383460e-02, -1.12211611e-02,\n",
            "       -3.95821780e-02, -2.35070456e-02, -3.81451622e-02,  9.05661359e-02,\n",
            "        3.00659221e-02, -3.48320045e-02, -1.38716325e-02,  4.78101447e-02,\n",
            "        9.87006724e-03,  5.19245258e-03, -2.98407883e-03,  1.21513251e-02,\n",
            "       -2.58406512e-02, -9.56419706e-02, -4.79647331e-02, -1.71355233e-02,\n",
            "       -3.36031392e-02, -7.07853660e-02,  1.53208133e-02, -3.82107403e-03,\n",
            "       -1.26519809e-02,  4.39634174e-02, -2.30232626e-03,  5.84753305e-02,\n",
            "        2.26621088e-02,  2.84288879e-02, -1.42149813e-02,  2.11793394e-03,\n",
            "       -3.67405824e-02,  1.48163028e-02,  8.55381489e-02, -4.71034534e-02,\n",
            "        2.31766775e-02, -2.59288978e-02,  1.19116597e-01,  6.93866834e-02],\n",
            "      dtype=float32), {'url': 'https://adf.org.au/drug-facts/amyl-nitrite/', 'title': 'amyl nitrite', 'description': 'amyl nitrites effects, a depressant known for a quick, euphoric rush. learn about its recreational use, risks, and impact on the mind and body.', 'last_updated': '2023-11-23T00:00:00'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk_embeddings: list of tuples where the first element is the embedding\n",
        "print(f\"Type of first embedding: {type(chunk_embeddings[0][0])}\")\n",
        "print(f\"Sample embedding: {chunk_embeddings[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89iqZfrx6hYt",
        "outputId": "85cd8c8c-0648-4dc3-baa8-e90357b81b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of first embedding: <class 'numpy.ndarray'>\n",
            "Sample embedding: [-7.55856931e-02 -4.98172343e-02  4.40601818e-03  7.41399406e-03\n",
            "  8.92868638e-03 -8.50624442e-02  9.43308547e-02 -1.19197657e-02\n",
            "  1.30912796e-01 -7.72167593e-02 -7.58649781e-02  2.29869448e-02\n",
            " -8.12717080e-02  8.66935030e-02 -8.45631361e-02  5.80974072e-02\n",
            "  2.80641112e-02 -4.32347804e-02  1.84224620e-02  9.98330042e-02\n",
            "  3.31367701e-02  6.14176132e-02 -2.84463298e-02  1.28190508e-02\n",
            " -4.67867702e-02  8.00715294e-03 -2.51103137e-02 -1.94146372e-02\n",
            "  5.87008707e-03 -3.46222743e-02  8.65346715e-02 -1.20327994e-02\n",
            " -8.57718587e-02  1.78273432e-02 -2.91611031e-02  2.27504503e-02\n",
            " -8.88954625e-02  3.31952460e-02 -4.91235964e-02  3.13298590e-02\n",
            "  3.85471396e-02 -5.50916381e-02 -7.59686604e-02  2.50346400e-03\n",
            "  3.44036520e-03  1.46877477e-02 -5.49393408e-02 -5.94010623e-03\n",
            "  1.21789286e-02 -5.25474995e-02 -2.71602478e-02 -8.16488788e-02\n",
            "  1.55356934e-03  1.00651328e-02  4.41658758e-02 -7.46629983e-02\n",
            " -4.01593745e-02 -5.83030768e-02 -7.09550083e-02  5.75101329e-03\n",
            "  4.55508754e-02  7.98800811e-02 -1.63203720e-02 -4.61356230e-02\n",
            " -4.74116355e-02  3.11569963e-02  3.65474746e-02 -3.22106108e-02\n",
            "  3.78978960e-02 -9.77434590e-02 -6.09039403e-02 -5.48158884e-02\n",
            "  4.24948446e-02  1.17512971e-01 -7.21909553e-02 -1.29575087e-02\n",
            "  5.31016700e-02 -2.98486389e-02  2.67078169e-02  6.11506868e-04\n",
            "  1.17572144e-01  1.08651556e-01  6.22258410e-02  4.88193668e-02\n",
            "  5.56807853e-02  5.51531790e-03 -6.29165396e-03  2.19700132e-02\n",
            " -1.41988071e-02  8.43194127e-03  2.83571966e-02  7.62485191e-02\n",
            " -4.85594980e-02 -2.53615752e-02  9.25618038e-02 -3.30247879e-02\n",
            " -8.12857747e-02  1.99189186e-02 -2.85850093e-02  1.08829066e-02\n",
            "  4.34788913e-02  4.67065349e-02 -7.51488730e-02 -9.99765620e-02\n",
            " -6.47526085e-02  9.25300294e-04  8.00900683e-02  1.88204423e-02\n",
            "  9.84922722e-02  3.27717997e-02 -5.68991415e-02 -4.72274423e-03\n",
            " -1.18042564e-03 -5.41620143e-02 -1.05654612e-01  4.24562506e-02\n",
            " -8.66052136e-02  4.00355943e-02 -3.19813075e-03  5.04195765e-02\n",
            " -2.55357642e-02 -4.06582467e-02  2.38036811e-02 -3.76922302e-02\n",
            "  4.73923199e-02  6.50111660e-02 -5.63416891e-02  1.82021259e-33\n",
            "  2.54428051e-02  3.35196033e-02  2.37868652e-02  4.34939787e-02\n",
            " -2.30908655e-02  5.36501370e-02 -2.59392057e-02 -6.92080557e-02\n",
            "  4.93142083e-02 -1.23632327e-02  1.96059537e-03 -9.11846459e-02\n",
            " -1.11115955e-01  9.25658494e-02  3.84097546e-02  2.62093777e-03\n",
            " -3.05719301e-02 -1.74474344e-02  6.11169264e-02 -1.52598731e-02\n",
            "  7.50749558e-03  1.01722836e-01 -8.71588141e-02 -1.89241162e-03\n",
            " -9.76208597e-02  3.33037004e-02 -1.35552764e-01  1.57694053e-02\n",
            "  7.30053857e-02 -1.96537049e-03  4.45267335e-02 -3.18352580e-02\n",
            " -2.78864186e-02 -2.25131363e-02 -4.29142043e-02  5.48678301e-02\n",
            "  1.27619412e-02  3.20426486e-02  3.70428013e-03 -2.33562384e-02\n",
            "  2.90599111e-02  3.60305272e-02  2.32244022e-02  6.04437031e-02\n",
            " -2.60544363e-02  5.30076623e-02 -9.82638747e-02  8.47208351e-02\n",
            "  1.91684943e-02 -4.46677096e-02  4.92494851e-02 -3.13807800e-02\n",
            " -1.06481826e-02 -2.76641026e-02 -6.68990910e-02  9.22702625e-02\n",
            " -2.54876390e-02 -8.47853199e-02  1.14209682e-01  1.54997036e-02\n",
            " -6.87201917e-02 -1.06851440e-02  4.31999937e-02 -3.41381021e-02\n",
            "  7.06150196e-03 -1.22468267e-02 -6.53815269e-02 -5.91827370e-02\n",
            " -1.72540452e-03  3.85097675e-02 -2.25927420e-02  1.77144706e-02\n",
            "  8.51355121e-02 -4.80911173e-02  7.47912144e-03 -2.80815680e-02\n",
            "  4.66976613e-02 -5.39767882e-03  3.41712050e-02 -1.05153238e-02\n",
            "  4.67626378e-02 -9.47765037e-02  3.66203897e-02 -1.45883681e-02\n",
            " -3.69103514e-02 -2.66918726e-03  2.10993905e-02  2.37312657e-03\n",
            " -4.80413623e-03 -1.00648834e-03  1.88995227e-02 -6.83570951e-02\n",
            " -5.86198382e-02 -9.03866887e-02 -1.47074461e-02 -2.95297773e-33\n",
            "  9.96574610e-02 -7.41303340e-02 -3.29420157e-02  1.12482058e-02\n",
            "  5.69108352e-02  4.38263714e-02  4.61068703e-03  1.81196090e-02\n",
            " -1.98316458e-03  1.75517462e-02  5.63797653e-02 -1.81709006e-02\n",
            "  4.04300578e-02  1.02905706e-01 -1.30982986e-02  2.85809152e-02\n",
            " -2.19541565e-02  1.34726977e-02 -8.76846816e-03  6.05056155e-03\n",
            " -5.87195680e-02  8.28628987e-02  4.84402291e-03  6.40980573e-03\n",
            "  9.08816885e-03  3.57275270e-02 -1.45419510e-02 -7.56173134e-02\n",
            "  6.14045821e-02  4.14782539e-02  4.49306108e-02  5.99528514e-02\n",
            " -3.35620604e-02 -9.91566852e-02 -8.94378591e-03 -9.72108857e-04\n",
            "  5.02706356e-02 -1.38031438e-01 -9.65235829e-02 -6.36599809e-02\n",
            "  4.96886782e-02  1.84673369e-02  4.57875505e-02  1.16216242e-02\n",
            " -2.84468047e-02  6.47737831e-02 -4.88310680e-02 -7.18710572e-02\n",
            "  1.41224731e-02  3.78240757e-02  4.18470949e-02  3.46800461e-02\n",
            "  9.03773529e-04  9.44927335e-02 -8.18011165e-03 -6.75593363e-03\n",
            " -6.77098557e-02 -2.34641917e-02 -3.19373831e-02  3.51338275e-02\n",
            " -5.59894145e-02  5.20989001e-02 -9.15706251e-03 -6.92858323e-02\n",
            "  6.05507707e-03 -2.19487585e-02 -9.96983144e-03  6.08671829e-02\n",
            "  7.20532909e-02 -7.07478672e-02 -4.53523174e-02  4.45670374e-02\n",
            "  8.02534670e-02  5.86334206e-02  4.14301604e-02 -2.62926449e-03\n",
            "  3.90052758e-02 -6.20042942e-02  2.25082859e-02 -1.26868086e-02\n",
            "  1.12529984e-02  2.29063518e-02 -5.94704188e-02 -2.25142669e-02\n",
            " -4.97760065e-02 -3.60729061e-02  5.02931029e-02  1.46904260e-01\n",
            " -4.00597379e-02 -5.33013642e-02  8.67377501e-03 -4.14737947e-02\n",
            " -2.96532139e-02  7.01613352e-02 -2.68920548e-02 -4.93088876e-08\n",
            " -4.93899435e-02 -9.66052040e-02  4.93220799e-02 -2.01057307e-02\n",
            " -7.22520724e-02 -1.21458266e-02  9.53720212e-02  3.64760123e-02\n",
            " -1.01684046e-03 -1.13081587e-02  4.83176857e-03  9.23372656e-02\n",
            " -5.17147779e-02 -1.43987243e-03  4.61948244e-03  4.05104049e-02\n",
            " -1.68704689e-02 -1.42748859e-02 -6.35459507e-03 -5.78819513e-02\n",
            " -3.32531109e-02  3.52577120e-02 -1.91340130e-02  1.51748126e-02\n",
            "  3.90341468e-02 -3.14280502e-02  1.66383460e-02 -1.12211611e-02\n",
            " -3.95821780e-02 -2.35070456e-02 -3.81451622e-02  9.05661359e-02\n",
            "  3.00659221e-02 -3.48320045e-02 -1.38716325e-02  4.78101447e-02\n",
            "  9.87006724e-03  5.19245258e-03 -2.98407883e-03  1.21513251e-02\n",
            " -2.58406512e-02 -9.56419706e-02 -4.79647331e-02 -1.71355233e-02\n",
            " -3.36031392e-02 -7.07853660e-02  1.53208133e-02 -3.82107403e-03\n",
            " -1.26519809e-02  4.39634174e-02 -2.30232626e-03  5.84753305e-02\n",
            "  2.26621088e-02  2.84288879e-02 -1.42149813e-02  2.11793394e-03\n",
            " -3.67405824e-02  1.48163028e-02  8.55381489e-02 -4.71034534e-02\n",
            "  2.31766775e-02 -2.59288978e-02  1.19116597e-01  6.93866834e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import VectorParams, Distance\n",
        "import os\n",
        "\n",
        "qdrant_client = QdrantClient(qdrant_domain, api_key=qdrant_key_token)\n",
        "\n",
        "# Define the collection name\n",
        "collection_name = \"bot_all_MiniLM_L6_v2\"\n",
        "os.environ[\"qdrant_embeddings\"] = collection_name\n",
        "\n",
        "# Create Collection\n",
        "qdrant_client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    # vectors_config=vectors_config\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.EUCLID),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjwmPAI45CSK",
        "outputId": "96578609-381a-4ceb-ed41-5b4db2aab683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Insertion"
      ],
      "metadata": {
        "id": "-I8M5vpwv2Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_into_qdrant(client, collection_name, embedded_chunks, batch_size=100):\n",
        "    for i in range(0, len(embedded_chunks), batch_size):\n",
        "        batch = embedded_chunks[i:i+batch_size]\n",
        "        points = [{\n",
        "            \"id\": i + j,\n",
        "            \"vector\": embedding.tolist() if isinstance(embedding, np.ndarray) else embedding,\n",
        "            \"payload\": {k: (str(v) if not pd.isna(v) else \"\") for k, v in metadata.items()}  # Handle NaN values and ensure all values are strings\n",
        "        } for j, (embedding, metadata) in enumerate(batch)]\n",
        "\n",
        "        # Debugging print\n",
        "        print(f\"Inserting batch {i // batch_size} with starting index {i}\")\n",
        "        # Uncomment the next line to see the format of the first point in the batch\n",
        "        # print(points[0])\n",
        "\n",
        "        try:\n",
        "            client.upsert(collection_name=collection_name, points=points)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch starting at index {i}: {e}\")\n",
        "            break\n",
        "\n",
        "insert_into_qdrant(client=qdrant_client, collection_name=collection_name, embedded_chunks=chunk_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZILXxiHlwf_R",
        "outputId": "2157ba37-d3f9-48f5-a292-698f45d16b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserting batch 0 with starting index 0\n",
            "Inserting batch 1 with starting index 100\n",
            "Inserting batch 2 with starting index 200\n",
            "Inserting batch 3 with starting index 300\n",
            "Inserting batch 4 with starting index 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qdrant Check data\n",
        "- Count points in collection\n",
        "- Retrieve sample point\n",
        "- Run query/ retrieve and inspect the vector data"
      ],
      "metadata": {
        "id": "1ZSSXAS57bz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count points in collection\n",
        "def count_points_in_collection(client, collection_name):\n",
        "    response = client.count(collection_name=collection_name)\n",
        "    if hasattr(response, 'count'):\n",
        "        return response.count  # If the count is directly accessible\n",
        "    elif hasattr(response, 'result') and hasattr(response.result, 'count'):\n",
        "        return response.result.count  # If the count is inside a 'result' attribute\n",
        "    else:\n",
        "        raise AttributeError(\"Unable to find the count attribute in the response\")\n",
        "\n",
        "# Now, try to get the count again\n",
        "try:\n",
        "    point_count = count_points_in_collection(qdrant_client, collection_name)\n",
        "    print(f\"Number of points in the collection: {point_count}\")\n",
        "except AttributeError as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXroHEYw7Z3X",
        "outputId": "fbc771b9-4b68-4b36-e1c9-e3014aaf1062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of points in the collection: 495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve sample points\n",
        "def retrieve_sample_point(client, collection_name, point_id):\n",
        "    try:\n",
        "        # Call the retrieve method\n",
        "        response = client.retrieve(collection_name=collection_name, ids=[point_id])\n",
        "\n",
        "        # Directly check and return the response\n",
        "        if response:\n",
        "            return response\n",
        "        else:\n",
        "            return \"No response received from Qdrant.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving point: {e}\")\n",
        "        return \"An error occurred while retrieving the point.\"\n",
        "\n",
        "# Example usage\n",
        "sample_point_id = 100  # Replace with a valid ID from your collection\n",
        "sample_point = retrieve_sample_point(qdrant_client, collection_name, sample_point_id)\n",
        "print(f\"Sample point retrieved: {sample_point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za4o7zPY7v6k",
        "outputId": "5d61d70f-a95e-4785-fc40-f09f93750fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample point retrieved: [Record(id=100, payload={'description': 'celebrate finishing school safely at schoolies. stay with friends, pace drinking, watch belongings, know limits, and call 000 in emergencies.', 'last_updated': '2023-11-06T00:00:00', 'title': 'staying safe on schoolies', 'url': 'https://adf.org.au/insights/staying-safe-on-schoolies/'}, vector=None, shard_key=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "gO3GCJYU7YSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval Augmented Question Answering (QA) Setup:\n",
        "##### Supabase: Custom function that interacts with Supabase to fetch vectors and perform retrieval operations.\n",
        "*   RetrievalQA object: Combines a language model (llm) with the retriever to answer queries.\n",
        "*   chain_type: Specifies how the language model and retriever interact.\n",
        "\n",
        "Note: The exact nature of this interaction (how the retriever's results influence the language model's responses) depends on the chain_type."
      ],
      "metadata": {
        "id": "6PndVo9uQwnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model (LLM\n",
        "*   mistralai/Mistral-7B-Instruct-v0.1)"
      ],
      "metadata": {
        "id": "Y8FVMqumRUM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set Model\n",
        "# # mistralai/Mistral-7B-Instruct-v0.1\n",
        "# import torch\n",
        "# from transformers import BitsAndBytesConfig\n",
        "# quantization_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "9fb5MHcGRVvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test LLM Model\n",
        "*   Import components\n",
        "*   Create pipeline (text-generation) for model\n"
      ],
      "metadata": {
        "id": "ctYZfdMDRdOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # LLM model\n",
        "# model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "# model_4bit = AutoModelForCausalLM.from_pretrained( model_id, device_map=\"auto\",quantization_config=quantization_config, )\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# pipeline = pipeline(\n",
        "#         \"text-generation\",\n",
        "#         model=model_4bit,\n",
        "#         tokenizer=tokenizer,\n",
        "#         use_cache=True,\n",
        "#         device_map=\"auto\",\n",
        "#         max_length=500,\n",
        "#         do_sample=True,\n",
        "#         top_k=5,\n",
        "#         num_return_sequences=1,\n",
        "#         eos_token_id=tokenizer.eos_token_id,\n",
        "#         pad_token_id=tokenizer.eos_token_id,\n",
        "# )\n",
        "\n",
        "# # Pipline for model\n",
        "# llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "aedRJhG0RchZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm)"
      ],
      "metadata": {
        "id": "jXI9sC9pRfu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Templates for Queries\n",
        "*   Template for responses (context and question)\n",
        "*   Specific question and context for response generation stored in variable\n",
        "\n",
        "Note: This template reflects the ADFs focus on providing evidence-based information about minimising alcohol and drug harm. The chatbot is designed to assist users in navigating the website, offering information on ADF's programs, educational content, and aligning with the Australian National Drug Strategy."
      ],
      "metadata": {
        "id": "L2IkuByKRiK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# template = \"\"\"<s>[INST] You are a helpful, respectful, and well-informed assistant, specifically designed to guide users on the Alcohol and Drug Foundation website. Your responses should be concise, accurate, and relevant to the ADF's mission of inspiring positive change and delivering evidence-based approaches to minimize alcohol and drug harm. Answer the question below based on the context provided, ensuring the information aligns with ADF's principles and content available on the website.\n",
        "# {context}\n",
        "# {question} [/INST] </s>\n",
        "# \"\"\"\n",
        "# # Test template\n",
        "# question_p = \"\"\"What can you do?\"\"\"\n",
        "# context_p = \"\"\"As an AI assistant tailored for ADF, I focus on providing information and support related to harm minimisation and advocacy for people who use drugs. For YouGov poll data or insights, I would recommend reaching out directly to YouGov or accessing their official website where they publish their findings. If you have any questions related to the services ADF provides or if there's information I can offer you about harm minimisation, feel free to ask.\"\"\"\n",
        "\n",
        "# prompt = PromptTemplate(template=template, input_variables=[\"question\",\"context\"])\n",
        "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "# response = llm_chain.invoke({\"question\":question_p,\"context\":context_p})\n",
        "# response"
      ],
      "metadata": {
        "id": "OdBgMRrgRg6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Setup QA Chain\n",
        "# qa_chain = RetrievalQA(\n",
        "#     llm=llm,  # model\n",
        "#     retriever=retriever,  # retriever\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# # Qdrant\n",
        "# from langchain.chains import RetrievalQA\n",
        "# qa = RetrievalQA.from_chain_type(\n",
        "#     llm=llm,\n",
        "#     chain_type=\"stuff\",\n",
        "#     retriever=retriever,\n",
        "#     verbose=True\n",
        "# )"
      ],
      "metadata": {
        "id": "jOMfJue7Q3Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Queries\n",
        "#### RetrievalQA chain\n",
        "1. Processes the retrieving data based on the query\n",
        "2. Generates embeddings for the query\n",
        "3. Feeds this information into LLM (model)\n",
        "4. Produces response\n"
      ],
      "metadata": {
        "id": "0aW3MpggREbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def run_my_rag(qa, query):\n",
        "#     print(f\"Query: {query}\\n\")\n",
        "#     result = qa.invoke(query)\n",
        "#     print(\"\\nResult: \", result)"
      ],
      "metadata": {
        "id": "UFVIgbpqRE7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query =\"\"\" What is this company? \"\"\"\n",
        "# run_my_rag(qa, query)"
      ],
      "metadata": {
        "id": "zCb9tOeNRHec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}